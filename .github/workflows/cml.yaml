name: federated-learning-flower
on:
  push:
  workflow_dispatch:
permissions:
     contents: write
     actions: write
jobs:
  run:
    runs-on: ubuntu-latest
    # optionally use a convenient Ubuntu LTS + DVC + CML image
    #container: ghcr.io/iterative/cml:0-dvc2-base1
    steps:
      - uses: actions/checkout@v3
        with:
          lfs: true
          
      # Ensure LFS objects are properly pulled
      - name: Pull LFS objects
        run: |
          git lfs install
          git lfs pull
          
      # may need to setup NodeJS & Python3 on e.g. self-hosted
      - uses: actions/setup-node@v3
        with:
          node-version: '20'
      - uses: actions/setup-python@v4
        with:
          python-version: '3.8'
          cache: 'pip'
      - uses: iterative/setup-cml@v1
      
      # Cache conda/mamba environments
      - name: Cache conda environment
        uses: actions/cache@v3
        with:
          path: |
            ~/.conda
            ~/miniconda3
            ./venv
          key: ${{ runner.os }}-conda-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-conda-
      
      - name: Set up Python environment
        run: |
          python -m pip install --upgrade pip
          
          # Check if venv exists before creating
          if [ ! -d "venv" ]; then
            echo "Setting up virtual environment for the first time"
            pip install virtualenv
            virtualenv venv
          fi
          
          source venv/bin/activate
          
          # Check if mamba is installed
          if ! command -v mamba &> /dev/null; then
            echo "Installing mamba"
            pip install mamba
            mamba init
            source ~/.bashrc
            mamba create
            mamba activate
          fi
          
          # Install dependencies
          pip install -r requirements.txt
          
          # Check if main packages are installed to avoid reinstalling them
          if ! python -c "import xgboost" &> /dev/null; then
            pip install xgboost
          fi
          
          if ! python -c "import flwr" &> /dev/null; then
            pip install -U flwr["simulation"]
          fi
          
          if ! python -c "import ray" &> /dev/null; then
            pip install -U "ray[all]"
          fi
          
          if ! python -c "import torch" &> /dev/null; then
            pip install torch torchvision torchaudio
          fi
          
          if ! python -c "import hydra" &> /dev/null; then
            pip install hydra-core
          fi
          
          if ! python -c "import imblearn" &> /dev/null; then
            pip install imbalanced-learn
          fi
      
      - name: Install hyperopt
        run: |
          source venv/bin/activate
          pip install hyperopt
      
      - name: Run federated learning pipeline
        run: |
          source venv/bin/activate
          
          # Create output directories to ensure they exist
          mkdir -p outputs results tune_results
          
          # Run the federated learning with integrated Ray Tune hyperparameter optimization
          echo "Running federated learning pipeline with Random Forest and integrated Ray Tune optimization..."
          echo "This will optimize hyperparameters for Random Forest models during training..."
          
          # Enable tuning in the federated learning pipeline to integrate Ray Tune optimization using Random Forest
          python run.py +experiment=random_forest tuning.enabled=true
          
          # The optimized parameters will be automatically applied during training and testing
          echo "Ray Tune optimization completed and parameters applied to Random Forest federated learning models"
          
          # List what was created for debugging
          echo "Contents of outputs directory:"
          ls -la outputs/ || echo "outputs directory is empty or doesn't exist"
          
          echo "Contents of results directory:"
          ls -la results/ || echo "results directory is empty or doesn't exist"
          
          echo "Contents of tune_results directory:"
          ls -la tune_results/ || echo "tune_results directory is empty or doesn't exist"
      
      - name: Evaluate model performance
        run: |
          source venv/bin/activate
          # Evaluate model performance with integrated Ray Tune optimization
          echo "## Random Forest Federated Learning Model Performance with Ray Tune Optimization" > model_performance.md
          echo "" >> model_performance.md
          
          # Extract metrics from the results directory
          if [ -d "results" ]; then
            echo "### Random Forest Federated Learning Results with Optimized Hyperparameters" >> model_performance.md
            echo "" >> model_performance.md
            echo "| Metric | Value |" >> model_performance.md
            echo "| ------ | ----- |" >> model_performance.md
            
            # Extract and add key metrics if available
            for metric_file in $(find results -name "*.txt" | grep -i "metrics\|accuracy\|f1\|precision\|recall"); do
              metric_name=$(basename "$metric_file" .txt)
              metric_value=$(cat "$metric_file" | head -n 1)
              echo "| $metric_name | $metric_value |" >> model_performance.md
            done
          fi
          
          # Add Ray Tune optimization results from outputs or tune_results
          for tune_dir in "outputs" "tune_results"; do
            if [ -d "$tune_dir" ]; then
              # Look for best parameters files
              for params_file in $(find "$tune_dir" -name "best_params.json" -o -name "*best*.json" | head -n 1); do
                if [ -f "$params_file" ]; then
                  echo "" >> model_performance.md
                  echo "### Integrated Ray Tune Optimization Results" >> model_performance.md
                  echo "" >> model_performance.md
                  echo "Optimized Random Forest hyperparameters:" >> model_performance.md
                  echo '```json' >> model_performance.md
                  cat "$params_file" >> model_performance.md
                  echo '```' >> model_performance.md
                  break
                fi
              done
            fi
          done

      - name: Debug git status before commit
        run: |
          echo "=== Current git status ==="
          git status
          
          echo "=== Files in outputs directory ==="
          find outputs -type f 2>/dev/null || echo "No files in outputs directory"
          
          echo "=== Files in results directory ==="
          find results -type f 2>/dev/null || echo "No files in results directory"
          
          echo "=== Files in tune_results directory ==="
          find tune_results -type f 2>/dev/null || echo "No files in tune_results directory"
          
          echo "=== Git check-ignore on key directories ==="
          git check-ignore outputs/ || echo "outputs/ is NOT ignored"
          git check-ignore results/ || echo "results/ is NOT ignored" 
          git check-ignore tune_results/ || echo "tune_results/ is NOT ignored"
          
      - name: Commit results file
        run: |
          git config --local user.email "abde8473@stthomas.edu"
          git config --local user.name "moh-a-abde"
          
          # Force add all files in result directories using find to be more robust
          echo "Force adding all result files..."
          
          # Add tune_results directory and all its contents
          if [ -d "tune_results" ]; then
            git add -f tune_results/
            find tune_results -type f -exec git add -f {} \; 2>/dev/null || true
          fi
          
          # Add results directory and all its contents  
          if [ -d "results" ]; then
            git add -f results/
            find results -type f -exec git add -f {} \; 2>/dev/null || true
          fi
          
          # Add outputs directory and all its contents (excluding large model files)
          if [ -d "outputs" ]; then
            git add -f outputs/
            # Add files smaller than 100MB to avoid GitHub's file size limit
            find outputs -type f -size -100M -exec git add -f {} \; 2>/dev/null || true
            echo "Skipping large model files (>100MB) to avoid GitHub size limits"
          fi
          
          # Add model performance report
          git add model_performance.md 2>/dev/null || true
          
          # Add any other important files that might have been created
          git add -f *.json 2>/dev/null || true
          git add -f tuned_params.py 2>/dev/null || true
          
          # Check what files are staged for commit
          echo "Files staged for commit:"
          git status --porcelain
          
          # Commit all changes (only if there are changes)
          if [ -n "$(git status --porcelain)" ]; then
            git commit -m "Random Forest federated learning with integrated Ray Tune hyperparameter optimization ðŸš€"
            echo "Changes committed successfully"
          else
            echo "No changes to commit"
          fi

      - name: Push changes
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          force: true

      
